# -*- coding: utf-8 -*-
"""Smart Product Categorization with NLP and Zero-Shot Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10-5uRW8tSnBXmo-sFwCu7wWctnQmOUK2
"""

import pandas as pd

df = pd.read_csv('/content/walmart-products.csv')
df.head()

"""Note:
We start by importing pandas and loading our Walmart product data into a DataFrame. The head() function lets us preview the first few rows to understand the structure of our data.
"""

df = pd.read_csv('/content/walmart-products.csv')
df.head()

print(df['categories'].value_counts(dropna=False).head(20))
print("Number of unique cats:", df['categories'].nunique())
print("Missing cats values:", df['categories'].isnull().sum())

"""Here, we explore the categories column to see the most common category paths, count how many unique categories exist, and check for any missing values. This helps us understand the diversity and completeness of our category data."""

import ast

def parse_categories(cat_str):
    try:
        return ast.literal_eval(cat_str)
    except:
        return []

df['categories_list'] = df['categories'].apply(parse_categories)

"""The categories column is stored as a string that looks like a Python list. We use the ast.literal_eval function to safely convert this string into an actual Python list for easier processing."""

df['last_category'] = df['categories_list'].apply(lambda x: x[-1] if x else None)

"""We extract the most specific (last) category from each category path. This is often the most relevant category for matching with the product name."""

def keyword_match(row):
    if row['last_category'] is None:
        return False
    return row['last_category'].lower().replace(" ", "") in row['product_name'].lower().replace(" ", "")

df['simple_match'] = df.apply(keyword_match, axis=1)

"""Note:
This function checks if the last category (with spaces removed and in lowercase) appears in the product name (also lowercased and with spaces removed). It’s a quick way to see if there’s a basic match between the product name and its category.
"""

!pip install transformers

from transformers import pipeline

classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")

"""We install and import the Hugging Face Transformers library, then load a zero-shot classification pipeline using the BART large MNLI model. This model can judge how well a piece of text (like a product name) fits a given label (like a category), even if it wasn’t trained for this specific task."""

product_name = "Laura Mercier Caviar Stick Eye Color Sugar Frost 1.64g/0.05oz"
categories = ["Beauty", "Makeup", "Eye Makeup", "Eye Shadow", "Eye Shadow Stick"]
candidate_label = categories[-1]  # Use the most specific category

"""Here’s a demo: we test if a sample product name fits its most specific category using the zero-shot classifier. The result includes a confidence score indicating how well the model thinks the product matches the category."""

result = classifier(product_name, candidate_label)
print(result)

"""We repeat the process of extracting the last category from the category path, ensuring this works even if the column is still a string."""

import ast

def get_last_category(cat_str):
    try:
        cats = ast.literal_eval(cat_str)
        return cats[-1]
    except:
        return None

df['last_category'] = df['categories'].apply(get_last_category)

def match_category(row):
    if not row['last_category'] or not isinstance(row['product_name'], str):
        return None
    result = classifier(row['product_name'], row['last_category'])
    return result['scores'][0]  # Confidence score for the match

df['category_match_score'] = df.apply(match_category, axis=1)
print(df[['product_name', 'last_category', 'category_match_score']].head())

"""For each product, we use the zero-shot classifier to score how well the product name matches its most specific category. The score (between 0 and 1) reflects the model’s confidence in the match. This helps us identify products that might be miscategorized or need review.

Why Did It Take 12 Minutes for 5 Products?
This is due to how the zero-shot-classification pipeline from Hugging Face works:

Each call to the pipeline downloads and runs a large language model (BART-large-MNLI) under the hood.

For each product, the model must:

Tokenize the text,

Run it through a deep neural network,

Compute and return the result.

If you’re running this on Google Colab (CPU runtime), it’s slow—each prediction can take 1–3 minutes on CPU.

If you have a large dataset, running this for every row will be extremely time-consuming.
"""
